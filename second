def colored(r, g, b, text): # Highlight the output
    return "\033[38;2;{};{};{}m{} \033[38;2;255;255;255m".format(r, g, b, text)

# CODA reference -> KEGG 찾기
kegg_id = [] # KEGG reference id

sql_query = "SELECT * FROM reference where name='KEGG';" # first col = refid, third col = KEGG
cur.execute(sql_query)
kegg_ref_df = cur.fetchall()

print("Number of KEGG reference id = " + colored(255, 0, 0, str(len(symbol)))) 

for element in kegg_ref_df:
    kegg_id.append(element[0])
    
print("<Examples of the KEGG reference id>")
print(kegg_id[:10])

# List of edges that exist in kegg pathway
# Dataframe that contains edges with entrez id is "ppi_df_notna"
edge_ref_dict = {}

for i in range(len(ppi_df_notna)):
    row = ppi_df_notna.loc[i]
    edge_ref_dict[(row['leftentityid'], row['rightentityid'])] = row['referenceid']

print("<Example of edge reference dataframe row>")
dict(list(edge_ref_dict.items())[0:2])

# 그래서 ppi 네트워크에 들어간 edge들 중에 KEGG에서 가져온 edge들 있음?
ind = 0
for edge in edge_ref_dict:
    if edge_ref_dict[edge] in kegg_id:
        ind += 1
print("The number of KEGG interaction = " + str(ind))

# 앞서 구한 "Dijkstra path length" vs "Shortest path length"
# Parkinson's disease + Parkinsonian disease 유전자들 한꺼번에 보자
print("Disease genes examples : " + str(pd_gene[:5]) + "\n")

proximity_dict_SP = {}

start = time.time()

for drug in drug_gene_dict.keys():
    multiple_target_distance = []
    for target_gene in drug_gene_dict[drug]:
        distance_list = []
        for disease_gene in pd_gene:
            if target_gene in ppi_g.nodes and disease_gene in ppi_g.nodes:
                distance_list.append(nx.shortest_path_length(ppi_g, target_gene, disease_gene))
        multiple_target_distance.append(min(distance_list))

    proximity_dict_SP[drug] = np.mean(multiple_target_distance) # proximity 평균
        
print("time :", time.time() - start)

# 앞서 구한 "Dijkstra path length" vs "Shortest path length"
# Parkinson's disease + Parkinsonian disease 유전자들 한꺼번에 보자
print("Disease genes examples : " + str(pd_gene[:5]) + "\n")

proximity_dict_DJ = {}

start = time.time()

for drug in drug_gene_dict.keys():
    multiple_target_distance = []
    for target_gene in drug_gene_dict[drug]:
        distance_list = []
        for disease_gene in pd_gene:
            if target_gene in ppi_g.nodes and disease_gene in ppi_g.nodes:
                distance_list.append(nx.dijkstra_path_length(ppi_g, target_gene, disease_gene))
        multiple_target_distance.append(min(distance_list))

    proximity_dict_DJ[drug] = np.mean(multiple_target_distance) # proximity 평균
        
print("time :", time.time() - start)

# Because of type difference? Yes!

for i in range(len(kegg_id)):
    kegg_id[i] = int(kegg_id[i])
ind = 0

for edge in edge_ref_dict:
    if edge_ref_dict[edge] in kegg_id:
        ind += 1
        
print("The number of KEGG interaction = " + str(ind))

print("The number of KEGG interaction / Total interaction = " + str(ind) + " / " + str(len(edge_ref_dict)))

# Add edge feature : dataframe 하나하나 읽어서 우선 weight 1로 하고, ref가 KEGG에 있으면, weight에 +1

# 전체 PPI edge들의 weight를 1로 세팅
nx.set_edge_attributes(ppi_g, 1, "weight")

start = time.time()

# edge들의 reference id가 KEGG에 있다면, 기존 weight에 1을 더한다.
for edge in edge_ref_dict:
    if edge_ref_dict[edge] in kegg_id:
        source = edge[0]
        target = edge[1]
        ppi_g[source][target]['weight'] += 1
        
print("time :", time.time() - start)

# 실제 KEGG pathway에 reference가 있는 edge들에 weight가 잘 반영되었는지 확인

# reference로 KEGG를 갖는 edge들은 무엇이 있을까?
kegg_edge = []

for edge in edge_ref_dict:
    if edge_ref_dict[edge] in kegg_id:
        kegg_edge.append(edge)

kegg_edge[:10]

for edge in kegg_edge:
    if ppi_g.get_edge_data(edge[0], edge[1])["weight"] > 2: # more than one reference
        print(ppi_g.get_edge_data(edge[0], edge[1])["weight"])
        
ppi_g.get_edge_data('596', '3708')["weight"]

# Weight를 역수로 해서 길이가 짧게 만들기
for edge in ppi_g.edges():
    ppi_g[edge[0]][edge[1]]['weight'] = 1/ppi_g[edge[0]][edge[1]]['weight']

# Dijkstra path length

# Drug-gene dictionary
print(list(drug_gene_dict.items())[:2])

# Disease-gene dictionary
print(list(disease_gene_dict.items())[:2])

# Parkinson's disease genes
pd_gene = disease_gene_dict['parkinson disease'] + disease_gene_dict['parkinsonian disorders']

proximity_dict = {}

start = time.time()

for drug in drug_gene_dict.keys():
    for disease in ['parkinson disease', 'parkinsonian disorders']:
        multiple_target_distance = []
        for target_gene in drug_gene_dict[drug]:
            distance_list = []
            for disease_gene in disease_gene_dict[disease]:
                if target_gene in ppi_g.nodes and disease_gene in ppi_g.nodes:
                    distance_list.append(nx.dijkstra_path_length(ppi_g, target_gene, disease_gene))
            multiple_target_distance.append(min(distance_list))

        proximity_dict[(drug, disease)] = np.mean(multiple_target_distance) # proximity 평균
        
print("time :", time.time() - start)
proximity_dict

# Shortest path length

SP_proximity_dict = {}

start = time.time()

for drug in drug_gene_dict.keys():
    for disease in ['parkinson disease', 'parkinsonian disorders']:
        multiple_target_distance = []
        for target_gene in drug_gene_dict[drug]:
            distance_list = []
            for disease_gene in disease_gene_dict[disease]:
                if target_gene in ppi_g.nodes and disease_gene in ppi_g.nodes:
                    distance_list.append(nx.shortest_path_length(ppi_g, target_gene, disease_gene))
            multiple_target_distance.append(min(distance_list))

        SP_proximity_dict[(drug, disease)] = np.mean(multiple_target_distance) # proximity 평균
        
print("time :", time.time() - start)
SP_proximity_dict

################################################################################
!pip install Bio

from Bio import SeqIO

seq = SeqIO.read("rcsb_pdb_4D2I.fasta", "fasta")
print(type(seq))
print(seq)

import xpdb2

xpdb2

from Bio.PDB import PDBParser
import xpdb2  # this is the module described below

# read
sloppyparser = PDBParser(
    PERMISSIVE=True, structure_builder=xpdb2.SloppyStructureBuilder()
)
structure = sloppyparser.get_structure("MD_system", "proteins_441/Q9Y696-MDL-Q9Y696.4-2yv9_A.pdb")
structure

import pandas as pd

skempi = pd.read_csv('SKEMPI_1.1.csv', delimiter = ';')
skempi.head()

a = []

for element in skempi['Mutation(s)_PDB']:
    a.append(element[1])

list(set(a))

# PDC code chain identifier correspond to the second letter of mutation?
ind = 0
for i in range(len(skempi)):
    row = skempi.loc[i]
    chain = row['Mutation(s)_PDB'][1]
    PDB_code = row['Protein']
    PDB_code_split = PDB_code.split('_')
    if chain == PDB_code_split[1] or chain == PDB_code_split[2]:
        pass
    else:
        ind += 1
        if ind < 5:
            print("No! chain is " + chain + " but PDB code is " + PDB_code)

print("\nThe number of inappropriate PPI is " + str(ind))
print("The number of total PPI is " + str(len(skempi)))

from Bio.PDB import *

pdbl = PDBList() 
pdbl.retrieve_pdb_file('1CSE', pdir = '.', file_format = 'mmCif')

parser = MMCIFParser(QUIET = True) 
data = parser.get_structure("1CSE", "1cse.cif")
data

pdbl = PDBList() 
pdbl.retrieve_pdb_file('1CSE', pdir = '.', file_format = 'pdb')

parser = PDBParser(PERMISSIVE = True, QUIET = True) 
data = parser.get_structure("1cse","pdb1cse.ent")
data
print(data.header.keys())
data.header["name"]
data.header["head"]

model = data.get_models() 
model
models = list(model) 
type(models[0]) 
chains = list(models[0].get_chains())
chains 
type(chains[0]) 
residue = list(chains[1].get_residues())
residue

# 1CSE 
pdbl = PDBList() 
pdbl.retrieve_pdb_file('1CSE', pdir = '.', file_format = 'pdb')

parser = PDBParser(PERMISSIVE = True, QUIET = True) 
data = parser.get_structure("1cse","pdb1cse.ent")

model = data.get_models() 
models = list(model)
chains = list(models[0].get_chains())
residue = list(chains[1].get_residues())
residue

# 1ACB
pdb2 = PDBList() 
pdb2.retrieve_pdb_file('1ACB', pdir = '.', file_format = 'pdb')

parser2 = PDBParser(PERMISSIVE = True, QUIET = True) 
data2 = parser2.get_structure("1acb","pdb1acb.ent")

model2 = data2.get_models() 
models = list(model2)
chains = list(models[0].get_chains())
residue = list(chains[1].get_residues())
residue

# 1SBN
pdb3 = PDBList() 
pdb3.retrieve_pdb_file('1SBN', pdir = '.', file_format = 'pdb')

parser3 = PDBParser(PERMISSIVE = True, QUIET = True) 
data3 = parser3.get_structure("1sbn","pdb1sbn.ent")

model3 = data3.get_models() 
models = list(model3)
chains = list(models[0].get_chains())
residue = list(chains[1].get_residues())
residue

# 1TM1
pdb4 = PDBList() 
pdb4.retrieve_pdb_file('1TM1', pdir = '.', file_format = 'pdb')

parser4 = PDBParser(PERMISSIVE = True, QUIET = True) 
data4 = parser4.get_structure("1tm1","pdb1tm1.ent")

model4 = data4.get_models() 
models = list(model4)
chains = list(models[0].get_chains())
residue = list(chains[1].get_residues())
residue

# 1Y33
pdb5 = PDBList() 
pdb5.retrieve_pdb_file('1Y33', pdir = '.', file_format = 'pdb')

parser5 = PDBParser(PERMISSIVE = True, QUIET = True) 
data5 = parser5.get_structure("1y33","pdb1y33.ent")

model5 = data5.get_models() 
models = list(model5)
chains = list(models[0].get_chains())
residue = list(chains[1].get_residues())
residue

# convert 3 letters amino acid to 1 letter amino acid
# dictionary 
amino_dict = {'CYS': 'C', 'ASP': 'D', 'SER': 'S', 'GLN': 'Q', 'LYS': 'K',
     'ILE': 'I', 'PRO': 'P', 'THR': 'T', 'PHE': 'F', 'ASN': 'N', 
     'GLY': 'G', 'HIS': 'H', 'LEU': 'L', 'ARG': 'R', 'TRP': 'W', 
     'ALA': 'A', 'VAL':'V', 'GLU': 'E', 'TYR': 'Y', 'MET': 'M'}
     
# PDB residue to sequence
sequence = ''
for element in residue:
    amino = element.get_resname()
    if amino != 'HOH':
        sequence += amino_dict[element.get_resname()]
    else:
        break
sequence

# skempi data - sequence
ind = 0
for i in range(len(skempi)):
    row = skempi.loc[i]
    chain = row['Mutation(s)_PDB'][1]
    PDB_code = row['Protein']
    PDB_code_split = PDB_code.split('_')
    if chain == PDB_code_split[1] or chain == PDB_code_split[2]:
        pass
    else:
        ind += 1
        if ind < 5:
            print("No! chain is " + chain + " but PDB code is " + PDB_code)
            
skempi2 = pd.read_csv('skempi_v2.csv', delimiter = ';')
skempi2.head()
a = []

for element in skempi2['Mutation(s)_PDB']:
    a.append(element[1])

list(set(a))

# PDC code chain identifier correspond to the second letter of mutation?
ind = 0
for i in range(len(skempi2)):
    row = skempi2.loc[i]
    chain = row['Mutation(s)_PDB'][1]
    PDB_code = row['#Pdb']
    PDB_code_split = PDB_code.split('_')
    if chain == PDB_code_split[1] or chain == PDB_code_split[2]:
        pass
    else:
        ind += 1
        if ind < 5:
            print("No! chain is " + chain + " but PDB code is " + PDB_code)

print("\nThe number of inappropriate PPI is " + str(ind))
print("The number of total PPI is " + str(len(skempi2)))

################################################################################

# Confidence로 edge에 weight 준 후 Dijkstra path length 구하기
# CODA의 evidence score 이용
# 전부다 manual curation임??
# What is the type of ppi_df_notna['evidencescore'] keys?
print("Type of evidence score type : " + str(type(ppi_df_notna['evidencescore'][200].keys())))

evidence_type = []
for evidence in ppi_df_notna['evidencescore']:
    if evidence != None: # No Nonetype
        if str(evidence.keys()) == "dict_keys(['Manual_Curation'])":
            pass
        else: #만약 evidence score가 Manual Curation이 아니라면?
            #print(str(evidence.keys())) # "Discrete level이었고, 엄청 많다.
            evidence_type.append(str(evidence.keys()))
print("\n")
print(list(set(evidence_type)))
print("\nOnly Discrete level & Manual curation!")
