# 앞서 구한 "Dijkstra path length" vs "Shortest path length"
# Parkinson's disease + Parkinsonian disease 유전자들 한꺼번에 보자
print("Disease genes examples : " + str(pd_gene[:5]) + "\n")

proximity_dict_SP = {}

start = time.time()

for drug in drug_gene_dict.keys():
    multiple_target_distance = []
    for target_gene in drug_gene_dict[drug]:
        distance_list = []
        for disease_gene in pd_gene:
            if target_gene in ppi_g.nodes and disease_gene in ppi_g.nodes:
                distance_list.append(nx.shortest_path_length(ppi_g, target_gene, disease_gene))
        multiple_target_distance.append(min(distance_list))

    proximity_dict_SP[drug] = np.mean(multiple_target_distance) # proximity 평균
        
print("time :", time.time() - start)

# 앞서 구한 "Dijkstra path length" vs "Shortest path length"
# Parkinson's disease + Parkinsonian disease 유전자들 한꺼번에 보자
print("Disease genes examples : " + str(pd_gene[:5]) + "\n")

proximity_dict_DJ = {}

start = time.time()

for drug in drug_gene_dict.keys():
    multiple_target_distance = []
    for target_gene in drug_gene_dict[drug]:
        distance_list = []
        for disease_gene in pd_gene:
            if target_gene in ppi_g.nodes and disease_gene in ppi_g.nodes:
                distance_list.append(nx.dijkstra_path_length(ppi_g, target_gene, disease_gene))
        multiple_target_distance.append(min(distance_list))

    proximity_dict_DJ[drug] = np.mean(multiple_target_distance) # proximity 평균
        
print("time :", time.time() - start)

######### Dijkstra path method #########
# Dictionary to dataframe
# 0. Parkinson's disease 치료에 쓰이는 drug 찾기
pd_drug = []
for element in drug_disease_pair:
    if element[1] in ['parkinson disease', 'parkinsonian disorders']:
        pd_drug.append(element[0])
        
# 1. Drug / Non-drug
label = []
ind = 0 # drug label이 잘 들어갔는지 확인
for drug in proximity_dict_DJ.keys():
    if drug in pd_drug:
        label.append("Drug")
        ind += 1
    else:
        label.append("Non-drug")
        
if ind == len(pd_drug):
    print("Good Job!")
else:
    print("PD drug in dictionary is " + str(ind) + " but actual pd drug is " + str(len(pd_drug)))
    
# 2. proximity list
distance = list(proximity_dict_DJ.values())

# 3. dictionary
for_boxplot = {}
for_boxplot['distance'] = distance
for_boxplot['label'] = label

# To dataframe
df = pd.DataFrame(for_boxplot)

######### Shortest path method #########
# 1. Drug / Non-drug
label_SP = []
ind_SP = 0 # drug label이 잘 들어갔는지 확인
for drug in proximity_dict_SP.keys():
    if drug in pd_drug:
        label_SP.append("Drug")
        ind_SP += 1
    else:
        label_SP.append("Non-drug")
        
if ind_SP == len(pd_drug):
    print("Good Job!")
else:
    print("PD drug in dictionary is " + str(ind_SP) + " but actual pd drug is " + str(len(pd_drug)))
    
# 2. proximity list
distance_SP = list(proximity_dict_SP.values())

# 3. dictionary
for_boxplot_SP = {}
for_boxplot_SP['distance'] = distance_SP
for_boxplot_SP['label'] = label_SP

# To dataframe
df_SP = pd.DataFrame(for_boxplot_SP)

# 일단 sns 들어간 코드 가져오기
import seaborn as sns
import matplotlib.pyplot as plt
#from statannot import add_stat_annotation
fig, axes = plt.subplots(1, 2)
######### Shortest path method #########
x2 = "label"
y2 = "distance"
order2 = ['Drug', 'Non-drug']
sns.boxplot(data=df_SP, x=x2, y=y2, order=order2, ax=axes[0])

######### Dijkstra path method #########
x = "label"
y = "distance"
order = ['Drug', 'Non-drug']
sns.boxplot(data=df, x=x, y=y, order=order, ax=axes[1])

'''
ax, test_results = add_stat_annotation(ax, data=df, x=x, y=y, order=order,
                                   box_pairs=[("Drug", "Non-drug")],
                                   test='Mann-Whitney', text_format='star', loc='outside', verbose=2)
'''
sns.despine() # 필요없는 axis border 제거
axes[0].set_title("Shortest")
axes[1].set_title("Dijkstra")

# Drug vs Non-drug p-value 구하기
import scipy.stats

######### Shortest path method #########
drug_SP = []
non_drug_SP = []
for drug in proximity_dict_SP.keys():
    if drug in pd_drug:
        drug_SP.append(proximity_dict_SP[drug])
    else:
        non_drug_SP.append(proximity_dict_SP[drug])
p_value_SP = scipy.stats.ttest_ind(drug_SP, non_drug_SP, equal_var=False)
print(p_value_SP)

######### Dijkstra path method #########
drug_DJ = []
non_drug_DJ = []
for drug in proximity_dict_DJ.keys():
    if drug in pd_drug:
        drug_DJ.append(proximity_dict_DJ[drug])
    else:
        non_drug_DJ.append(proximity_dict_DJ[drug])
p_value_DJ = scipy.stats.ttest_ind(drug_DJ, non_drug_DJ, equal_var=False)
print(p_value_DJ)
#scipy.stats.ttest_ind(avg_prox, avg_prox_false, equal_var=False)

################################################################################################################################################
from glob import glob
from tqdm import tqdm
#from rdkit import Chem
import numpy as np
import pandas as pd
import re
import shutil
import os

train = pd.read_csv("data/train_set.ReorgE.csv")
train.columns = ["index", "SMILES", "Reorg_g", "Reorg_ex"]

train.head()

if os.path.isdir("ex_file"):
    pass
else:
    os.mkdir("ex_file")

if os.path.isdir("g_file"):
    pass
else:
    os.mkdir("g_file")

train_mol = sorted(glob("data/mol_files/train_set/*.mol"))

for i in tqdm(train_mol):
    result = []
    tmp = open(i, 'r').read().split("\n")
    for j in tmp:
        tmp_ = re.sub(' +', ' ', j.lstrip()).split(' ')
        if len(tmp_) > 11:
            result.append(tmp_)
            
    file_name = i.split('/')[-1].split('.')[0]
    
    if "ex" in file_name:
        pd.DataFrame(result).to_csv(f"ex_file/{file_name}" + ".csv", index = False)
    elif "g" in file_name:
        pd.DataFrame(result).to_csv(f"g_file/{file_name}" + ".csv", index = False)
        
 max_len = 0
error = []
g_data, ex_data = [], []
mol = []

for i in tqdm(train[train.columns[0]]):
    tmp_g = pd.read_csv(f"g_file/{i}" + '_g.csv')

    if len(tmp_g) >= max_len:
        max_len = len(tmp_g)
        
    for j in tmp_g["3"]:
        mol.append(j)
        
mol_list = list(set(mol))
g_data, ex_data = [], []

def get_mol(data):
    if data in mol_list:
        return mol_list.index(data) + 1
    
    else:
        return -1

for i in tqdm(train[train.columns[0]]):
    tmp_g = pd.read_csv(f"g_file/{i}" + '_g.csv').iloc[:, :4]
    tmp_ex = pd.read_csv(f"ex_file/{i}" +'_ex.csv').iloc[:, :4]
    
    tmp_g["3"] = tmp_g["3"].apply(lambda x : get_mol(x))
    tmp_ex["3"] = tmp_ex["3"].apply(lambda x : get_mol(x))
    
    tmp_g = np.array(tmp_g)
    tmp_ex = np.array(tmp_ex)
    
    if max_len != len(tmp_g):
        tmp_g = np.concatenate((tmp_g, np.array([[0] * 4] * (max_len-tmp_g.shape[0]))))
        tmp_ex = np.concatenate((tmp_ex, np.array([[0] * 4] * (max_len - tmp_ex.shape[0]))))
    elif max_len == len(tmp_g):
        tmp_g = tmp_g
        tmp_ex = tmp_ex
    
    g_data.append(tmp_g)
    ex_data.append(tmp_ex)
    
g_data = np.array(g_data).reshape(len(g_data), -1)
ex_data = np.array(ex_data).reshape(len(ex_data), -1)

train_x = np.concatenate((g_data, ex_data), axis = 1)
train_y = np.array(train.loc[:, ["Reorg_g", "Reorg_ex"]])

print(train_x.shape)
print(train_y.shape)

!pip install lightgbm
from sklearn.linear_model import LinearRegression
from sklearn.multioutput import MultiOutputRegressor
from sklearn.ensemble import RandomForestRegressor
import lightgbm as lgb

LR = MultiOutputRegressor(lgb.LGBMRegressor(random_state=42, n_estimators=1000, max_depth=61, learning_rate=0.075)).fit(train_x, train_y)

if os.path.isdir("test_ex_file"):
    pass
else:
    os.mkdir("test_ex_file")

if os.path.isdir("test_g_file"):
    pass
else:
    os.mkdir("test_g_file")

test_mol = sorted(glob("data/mol_files/test_set/*.mol"))

for i in tqdm(test_mol):
    result = []
    tmp = open(i, 'r').read().split("\n")
    for j in tmp:
        tmp_ = re.sub(' +', ' ', j.lstrip()).split(' ')
        if len(tmp_) > 11:
            result.append(tmp_)

    file_name = i.split('/')[-1].split('.')[0]

    if "ex" in file_name:
        pd.DataFrame(result).to_csv(f"test_ex_file/{file_name}" + ".csv", index = False)
    elif "g" in file_name:
        pd.DataFrame(result).to_csv(f"test_g_file/{file_name}" + ".csv", index = False)
        
test = pd.read_csv("data/test_set.csv")

test_g, test_ex = [], []

for i in tqdm(test[test.columns[0]]):
    tmp_g = pd.read_csv(f"test_g_file/{i}" + '_g.csv').iloc[:, :4]
    tmp_ex = pd.read_csv(f"test_ex_file/{i}" +'_ex.csv').iloc[:, :4]
    
    tmp_g["3"] = tmp_g["3"].apply(lambda x : get_mol(x))
    tmp_ex["3"] = tmp_ex["3"].apply(lambda x : get_mol(x))
    
    tmp_g = np.array(tmp_g)
    tmp_ex = np.array(tmp_ex)
    
    if len(tmp_g) < max_len:
        tmp_g = np.concatenate((tmp_g, np.array([[0] * 4] * (max_len-tmp_g.shape[0]))))
        tmp_ex = np.concatenate((tmp_ex, np.array([[0] * 4] * (max_len - tmp_ex.shape[0]))))
    elif len(tmp_g) == max_len:
        pass
    else:
        tmp_g = tmp_g[:max_len]
        tmp_ex = tmp_ex[:max_len]
    
    test_g.append(tmp_g)
    test_ex.append(tmp_ex)
    
test_g = np.array(test_g).reshape(len(test_g), -1)
test_ex = np.array(test_ex).reshape(len(test_ex), -1)

test_x = np.concatenate((test_g, test_ex), axis = 1)

print(test_x.shape)

pred = LR.predict(test_x)

submission = pd.read_csv("data/sample_submission.csv")

submission.head()

submission.loc[:, ["Reorg_g", "Reorg_ex"]] = pred

submission.to_csv("SAMSUNG_BASELINE.csv", index = False)
